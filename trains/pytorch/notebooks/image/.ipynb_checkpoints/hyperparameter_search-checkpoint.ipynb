{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute this in command line on all machines to be used as workers before initiating the hyperparamer search \n",
    "# ! pip install -U trains-agent==0.15.0\n",
    "# ! trains-agent daemon --queue default\n",
    "\n",
    "# pip install with locked versions\n",
    "# ! pip install -U pandas>=1.0.3\n",
    "# ! pip install -U trains>=0.16.2\n",
    "# ! pip install -U optuna==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trains.automation import UniformParameterRange, UniformIntegerParameterRange\n",
    "from trains.automation import HyperParameterOptimizer\n",
    "from trains.automation.optuna import OptimizerOptuna\n",
    "\n",
    "from trains import Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINS Task: overwriting (reusing) task id=adfb92750a4545b5a73ef857e123f38a\n",
      "2020-10-07 01:00:26,026 - trains.Repository Detection - WARNING - Can't get branch information for git repo in /home/tc/Programming/Python/Miniconda3/envs/ml-training/lib/python3.8/site-packages\n",
      "2020-10-07 01:00:26,034 - trains.Repository Detection - WARNING - Can't get commit information for git repo in /home/tc/Programming/Python/Miniconda3/envs/ml-training/lib/python3.8/site-packages\n",
      "2020-10-07 01:00:26,046 - trains.Repository Detection - WARNING - Can't get root information for git repo in /home/tc/Programming/Python/Miniconda3/envs/ml-training/lib/python3.8/site-packages\n",
      "2020-10-07 01:00:26,055 - trains.Repository Detection - WARNING - Can't get status information for git repo in /home/tc/Programming/Python/Miniconda3/envs/ml-training/lib/python3.8/site-packages\n",
      "2020-10-07 01:00:26,074 - trains.Repository Detection - WARNING - Can't get diff information for git repo in /home/tc/Programming/Python/Miniconda3/envs/ml-training/lib/python3.8/site-packages\n",
      "2020-10-07 01:00:26,083 - trains.Repository Detection - WARNING - Can't get modified information for git repo in /home/tc/Programming/Python/Miniconda3/envs/ml-training/lib/python3.8/site-packages\n",
      "TRAINS results page: http://34.122.153.228:80/projects/c8f1d52eb233454a8e6ae9968f3dcfd2/experiments/adfb92750a4545b5a73ef857e123f38a/output/log\n"
     ]
    }
   ],
   "source": [
    "task = Task.init(project_name='Hyperparameter Optimization with Optuna',\n",
    "                 task_name='Hyperparameter Search',\n",
    "                 task_type=Task.TaskTypes.optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "### Don't forget to replace this default id with your own task id ###\n",
    "#####################################################################\n",
    "TEMPLATE_TASK_ID = 'adfb92750a4545b5a73ef857e123f38a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-07 01:01:01,353 - trains.automation.optimization - WARNING - Could not find requested hyper-parameters ['number_of_epochs', 'batch_size', 'dropout', 'base_lr'] on base task adfb92750a4545b5a73ef857e123f38a\n",
      "2020-10-07 01:01:01,787 - trains.automation.optimization - WARNING - Could not find requested metric ('accuracy', 'total') report on base task adfb92750a4545b5a73ef857e123f38a\n"
     ]
    }
   ],
   "source": [
    "optimizer = HyperParameterOptimizer(\n",
    "    base_task_id=TEMPLATE_TASK_ID,  # This is the experiment we want to optimize\n",
    "    # here we define the hyper-parameters to optimize\n",
    "    hyper_parameters=[\n",
    "        UniformIntegerParameterRange('number_of_epochs', min_value=2, max_value=12, step_size=2),\n",
    "        UniformIntegerParameterRange('batch_size', min_value=2, max_value=16, step_size=2),\n",
    "        UniformParameterRange('dropout', min_value=0, max_value=0.5, step_size=0.05),\n",
    "        UniformParameterRange('base_lr', min_value=0.00025, max_value=0.01, step_size=0.00025),\n",
    "    ],\n",
    "    # setting the objective metric we want to maximize/minimize\n",
    "    objective_metric_title='accuracy',\n",
    "    objective_metric_series='total',\n",
    "    objective_metric_sign='max',  # maximize or minimize the objective metric\n",
    "\n",
    "    # setting optimizer - trains supports GridSearch, RandomSearch, OptimizerBOHB and OptimizerOptuna\n",
    "    optimizer_class=OptimizerOptuna,\n",
    "    \n",
    "    # Configuring optimization parameters\n",
    "    execution_queue='default',  # queue to schedule the experiments for execution\n",
    "    max_number_of_concurrent_tasks=2,  # number of concurrent experiments\n",
    "    optimization_time_limit=60.,  # set the time limit for the optimization process\n",
    "    compute_time_limit=120,  # set the compute time limit (sum of execution time on all machines)\n",
    "    total_max_jobs=20,  # set the maximum number of experiments for the optimization. \n",
    "                        # Converted to total number of iteration for OptimizerBOHB\n",
    "    min_iteration_per_job=15000,  # minimum number of iterations per experiment, till early stopping\n",
    "    max_iteration_per_job=150000,  # maximum number of iterations per experiment\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress report #0 completed, sleeping for 0.25 minutes\n",
      "2020-10-07 01:01:14,824 - trains.automation.optimization - INFO - Creating new Task: {'number_of_epochs': 6, 'batch_size': 6, 'dropout': 0.30000000000000004, 'base_lr': 0.00575}\n",
      "2020-10-07 01:01:15,142 - trains.automation.job - WARNING - Could not find queue named \"dan_queue\"\n",
      "2020-10-07 01:01:15,350 - trains.automation.optimization - INFO - Creating new Task: {'number_of_epochs': 4, 'batch_size': 4, 'dropout': 0.0, 'base_lr': 0.006750000000000001}\n",
      "2020-10-07 01:01:15,707 - trains.automation.job - WARNING - Could not find queue named \"dan_queue\"\n",
      "Progress report #1 completed, sleeping for 1.0 minutes\n"
     ]
    }
   ],
   "source": [
    "optimizer.set_report_period(1)  # setting the time gap between two consecutive reports\n",
    "optimizer.start()  \n",
    "optimizer.wait()  # wait until process is done\n",
    "optimizer.stop()  # make sure background optimization stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization is completed, print the top performing experiments id\n",
    "k = 3\n",
    "top_exp = optimizer.get_top_experiments(top_k=k)\n",
    "print('Top {} experiments are:'.format(k))\n",
    "for n, t in enumerate(top_exp, 1):\n",
    "    print('Rank {}: task id={} |result={}'\n",
    "          .format(n, t.id, t.get_last_scalar_metrics()['accuracy']['total']['last']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
